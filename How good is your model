How good is your model ?

Easiest way to check the accuracy of a model is by looking at the two R-squared values, namely Multiple R-squared and Adjusted R-squared.



Multiple R-squared:
------------------
Multiple R-squared = 1 – SSE/SST where:

SSE is the sum of square of residuals. Residual is the difference between the predicted value and the actual value.

SST is the total sum of squares. It is calculated by summing the squares of difference between the actual value and the mean value.


Adjusted R-squared:
------------------
Adjusted R-squared value is similar to the Multiple R-squared value,but it accounts for the number of variables. This means that the Multiple R-squared will always increase when a
new variable is added to the prediction model, but if the variable is a non-significant one, the Adjusted R-squared value will decrease.

R-squared value of 1 means that it is a perfect prediction model.

R-squared or R2 explains the degree to which your input variables explain the variation of your output / predicted variable. So, if R-square is 0.8, it means 80% of the variation in the output variable is explained by the input variables. So, in simple terms, higher the R squared, the more variation is explained by your input variables and hence better is your model.

However, the problem with R-squared is that it will either stay the same or increase with addition of more variables, even if 
they do not have any relationship with the output variables. This is where “Adjusted R square” comes to help. Adjusted R-square penalizes you for adding variables which do not improve your existing model.

Hence, if you are building Linear regression on multiple variable, it is always suggested that you use Adjusted R-squared 
to judge goodness of model. In case you only have one input variable, R-square and Adjusted R squared would be exactly same.
